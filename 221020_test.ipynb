{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Aruco tag(aruco.DICT_4X4_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Running cells with 'Python 3.6.9 64-bit' requires notebook and jupyter package.\n",
      "\u001b[1;31mRun the following command to install 'jupyter and notebook' into the Python environment. \n",
      "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
      "\u001b[1;31mor\n",
      "\u001b[1;31mconda install jupyter notebook -U'\n",
      "\u001b[1;31mClick <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# import cv2.aruco as aruco\n",
    "from cv2 import aruco\n",
    "\n",
    "#Aruco detection\n",
    "# cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "   ret, frame = cap.read()\n",
    "   gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "   aruco_dict = aruco.Dictionary_get(aruco.DICT_4X4_50)\n",
    "   arucoParameters = aruco.DetectorParameters_create()\n",
    "   corners, ids, rejectedImgPoints = aruco.detectMarkers(\n",
    "       gray, aruco_dict, parameters=arucoParameters)\n",
    "   print(ids)\n",
    "   if np.all(ids):\n",
    "     image = aruco.drawDetectedMarkers(frame,corners,ids)         \n",
    "     cv2.imshow('Display', image)\n",
    "   else:\n",
    "       display = frame\n",
    "       cv2.imshow('Display', display)\n",
    "      \n",
    "   if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "       break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take phota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# import cv2.aruco as aruco\n",
    "import time\n",
    "cap = cv2.VideoCapture(0)\n",
    "last_recorded_time = time.time()\n",
    "frame_count = 0\n",
    "\n",
    "while True: \n",
    " _, frame = cap.read()\n",
    " curr_time = time.time()\n",
    " cv2.imshow('Display', frame)\n",
    " if (curr_time - last_recorded_time >= 2.0):\n",
    "   cv2.imwrite('frame_{}.png'.format(frame_count), frame)\n",
    "   last_recorded_time = curr_time\n",
    "   frame_count+=1\n",
    " if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "   break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calibrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error:  0.03713254932182226\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "# size of each square is 35 mm\n",
    "square_size = 0.018 #in meters\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = (square_size * np.mgrid[0:9,0:6]).T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# images = glob.glob(r'/home/pi/project/calib_photos/*.png',)\n",
    "images = glob.glob(r'F:\\System Folders\\Desktop\\RP_reference\\RP_HW\\project221020\\*.png',)\n",
    "\n",
    "\n",
    "for fname in images:\n",
    "   img = cv2.imread(fname)\n",
    "   gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "   sample_im = gray\n",
    "   #cv2.imshow(gray)\n",
    "   # Find the chess board corners\n",
    "   chessboard_flags = cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE\n",
    "   flags = 0\n",
    "   flags |= cv2.CALIB_CB_ADAPTIVE_THRESH\n",
    "   flags |= cv2.CALIB_CB_NORMALIZE_IMAGE\n",
    "   [ret, corners] = cv2.findChessboardCorners(gray, (9, 6), flags)\n",
    "\n",
    "   # If found, add object points, image points (after refining them)\n",
    "   if (ret == True):\n",
    "       #print ('True')\n",
    "       objpoints.append(objp)\n",
    "       corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "       imgpoints.append(corners2) #these are the found corners\n",
    "\n",
    "       # Draw and display the corners\n",
    "       img = cv2.drawChessboardCorners(img, (9,6), corners2,ret)\n",
    "       cv2.imshow('img',img)\n",
    "       cv2.waitKey(100)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "\n",
    "# Undistortion\n",
    "# refine the camera matrix\n",
    "ii = -1\n",
    "for fname in images:\n",
    "   #if (fname==images[0]):\n",
    "   ii +=1\n",
    "   img = cv2.imread(fname)\n",
    "   h,  w = img.shape[:2]\n",
    "   newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "   dst1 = cv2.undistort(img, newcameramtx, dist, None, None)\n",
    "  \n",
    "   # testing if the matrix is right\n",
    "   # image_path1 = r'/home/pi/project/calib_photos/final/%i.png' % ii\n",
    "   image_path1 = r'F:\\System Folders\\Desktop\\RP_reference\\RP_HW\\project221020\\calib_photos\\%i.png' % ii\n",
    "   cv2.imwrite(image_path1, dst1)\n",
    "\n",
    "# path = r'/home/pi/project/picamera.yml'  #F:\\System Folders\\Desktop\\RP_reference\\RP_HW\\project221020\\*.png\n",
    "path = r'F:\\System Folders\\Desktop\\RP_reference\\RP_HW\\project221020\\picamera.yml' \n",
    "cv_file = cv2.FileStorage(path, cv2.FILE_STORAGE_WRITE)\n",
    "cv_file.write(\"new_matrix\", newcameramtx)\n",
    "cv_file.write(\"distortion_coef\", dist)\n",
    "\n",
    "cv_file.release()\n",
    "\n",
    "# Re-projection Error\n",
    "tot_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "   imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "   error = cv2.norm(imgpoints[i],imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
    "   tot_error += error\n",
    "\n",
    "print (\"total error: \", tot_error/len(objpoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV(4.6.0) D:\\bld\\libopencv_1661643075477\\work\\modules\\calib3d\\src\\calibration.cpp:1072: error: (-215:Assertion failed) CV_IS_MAT(objectPoints) && CV_IS_MAT(imagePoints) && CV_IS_MAT(A) && CV_IS_MAT(rvec) && CV_IS_MAT(tvec) in function 'cvFindExtrinsicCameraParams2'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import cv2\n",
    "import numpy as np\n",
    "import datetime\n",
    "from cv2 import aruco\n",
    "import glob\n",
    "import math\n",
    "import faulthandler; faulthandler.enable()\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "#IP = '192.168.0.246' #Emmettâ€™s Robot IP\n",
    "IP = '192.168.137.120' #Mahshid's Robot IP\n",
    "port = 5000\n",
    "marker_dimension = 0.046  #4.6 centimeter before\n",
    "worldx = 889 #508#-marker_dimension*1000 #millimeters\n",
    "worldy = 508 #401#-marker_dimension*1000 #millimeters\n",
    "# modify these based on your enviornment settings\n",
    "# robot_ID = 7\n",
    "# bottom_left = 31  #this is the origin - positivex: towards bottom right - positivey: towards top left\n",
    "# bottom_right = 32\n",
    "# top_left = 9\n",
    "# top_right = 20\n",
    "robot_ID = 5\n",
    "bottom_left = 1  #this is the origin - positivex: towards bottom right - positivey: towards top left\n",
    "bottom_right = 2\n",
    "top_left = 3\n",
    "top_right = 4\n",
    "\n",
    "\n",
    "# def UDP(IP,port,message):\n",
    "#    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) #IPv4 DNS server - UDP protocol\n",
    "#    sock.sendto(bytes(message, \"utf-8\"), (IP,port)) #self, data, address\n",
    "\n",
    "def getMarkerCenter(corners):\n",
    " px = (corners[0][0] + corners[1][0] + corners[2][0]+ corners[3][0]) * 0.25\n",
    " py = (corners[0][1] + corners[1][1] + corners[2][1]+ corners[3][1]) * 0.25\n",
    " return [px,py]\n",
    "\n",
    "def getMarkerRotation(corners):\n",
    " unit_x_axis = [1.,0.]\n",
    " center = getMarkerCenter(corners)\n",
    " right_edge_midpoint = (corners[1]+corners[2])/2.\n",
    " unit_vec = (right_edge_midpoint-center)/np.linalg.norm(right_edge_midpoint-center)\n",
    " angle = np.arccos(np.dot(unit_x_axis,unit_vec))\n",
    " return angle\n",
    "\n",
    "def inversePerspective(rvec, tvec):\n",
    "   R, _ = cv2.Rodrigues(rvec)\n",
    "   R = np.array(R).T #this was np.matrix but had error\n",
    "   invTvec = np.dot(-R, np.array(tvec))\n",
    "   invRvec, _ = cv2.Rodrigues(R)\n",
    "   return invRvec, invTvec\n",
    "def normalize(v):\n",
    "   if np.linalg.norm(v) == 0 : return v\n",
    "   return v / np.linalg.norm(v)\n",
    "\n",
    "\"\"\"\" the function gets the corners of an aruco marker in the camera space as the origin with its\n",
    "X (Green) and Y (Red) axis. The origin is the bottom left corner, the coordinate of the point is calculated\n",
    "in relation to this origin \"\"\"\n",
    "def findWorldCoordinate(originCorners, point):\n",
    "   zero = np.array(originCorners[3]) #bottom left as the origin - check the data structure\n",
    "   x = (np.array(originCorners[0]) - zero)  # bottom right - Green Axis -- throw out z\n",
    "   y = (np.array(originCorners[1]) - zero)   # top left - Red Axis -- throw out z\n",
    "   x = x[0][0:2]\n",
    "   y = y[0][0:2]\n",
    "   x = normalize(x)\n",
    "   y = normalize(y)\n",
    "   #print(\"x\", x)\n",
    "   vec = (point - zero)[0][0:2]\n",
    "   #print(\"vec\", vec)\n",
    "   vecNormal = normalize(vec)\n",
    "   cosX = np.dot(x,vecNormal)\n",
    "   cosY = np.dot(y,vecNormal)\n",
    "   xW = np.linalg.norm(vec) * cosX\n",
    "   yW = np.linalg.norm(vec) * cosY\n",
    "   return [xW, yW]\n",
    "################################\n",
    "try:\n",
    "   # Getting the camera calibration information\n",
    "   path = r'/home/pi/ECE-5725/camera_codes/picamera.yml'\n",
    "   cv_file = cv2.FileStorage(path, cv2.FILE_STORAGE_READ)\n",
    "   new_matrix = cv_file.getNode(\"new_matrix\").mat()\n",
    "   dist_matrix = cv_file.getNode(\"distortion_coef\").mat()\n",
    "   mtx = cv_file.getNode(\"matrix\").mat()\n",
    "   cv_file.release()\n",
    "\n",
    "   found_dict_pixel_space = {}\n",
    "   found_dict_camera_space = {}\n",
    "   found_dict_world_space = {}\n",
    "   found_dict_homography_space = {}\n",
    "   final_string = \"\"\n",
    "   originRvec = np.array([0,0,1])\n",
    "   markerRvec= np.array([0,0,0])\n",
    "\n",
    " # read aruco markers and create dictionary\n",
    "   aruco_source_path = glob.glob(r'/home/pi/ECE-5725/camera_codes/aruco/*.jpg', )\n",
    "   aruco_source = []\n",
    "   for ar in aruco_source_path:\n",
    "       im_src = cv2.imread(ar)\n",
    "       aruco_source.append(im_src)\n",
    "   aruco_dict = aruco.Dictionary_get(aruco.DICT_4X4_50)\n",
    "  \n",
    "   cap = cv2.VideoCapture(0)\n",
    "   #pool = mp.Pool(mp.cpu_count()) # init pool for multiprocessing\n",
    "  \n",
    "   while True:\n",
    "       t0 = time.time()\n",
    "       #ret, frame = cap.read() # read frame\n",
    "       ret, image = cap.read() # read frame\n",
    "       #cv2.imshow('frame', frame)\n",
    "       t1 = time.time()-t0\n",
    "       #----aruco detection-------------------\n",
    "       gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # converts image color space from BRG to grayscale\n",
    "       t2 = time.time()-t0\n",
    "       data = aruco.detectMarkers(gray, aruco_dict) # detect aruco markers\n",
    "      \n",
    "       t3 = time.time()-t0\n",
    "       corners = data[0] # corners of found aruco markers\n",
    "       ids = data[1] # ids of found aruco markers\n",
    "       originIDglobal = 0\n",
    "       if np.all(ids): # if any markers were found\n",
    "           #print(\"found one!\")\n",
    "           t4 = time.time()-t0\n",
    "           result = aruco.estimatePoseSingleMarkers(corners, marker_dimension, new_matrix, dist_matrix) # estimate the pose of the markers\n",
    "           rvecs = result[0] # rotation vectors of markers\n",
    "           tvecs = result[1] # translation vector of markers\n",
    "           imageCopy = image\n",
    "\n",
    "           #setting bottom_left as the origin\n",
    "           if bottom_left in ids:\n",
    "               originID = np.where(ids == bottom_left)[0][0]\n",
    "               originIDglobal = originID\n",
    "           else:\n",
    "               originID = originIDglobal\n",
    "           originCorners = corners[originID] # corners of the tag set as the origin\n",
    "           OriginCornersCamera = getCornerInCameraWorld(marker_dimension, rvecs[originID], tvecs[originID])[0] # origin tag corners in camera space\n",
    "           originRvec = rvecs[originID] # rotation vec of origin tag\n",
    "           originTvec = tvecs[originID] # translation vec of origin tag\n",
    "          \n",
    "           display = cv2.aruco.drawDetectedMarkers(imageCopy,corners,ids) # display is image copy with boxes drawn around the tags\n",
    "           t5 = time.time()-t0\n",
    "           for i in range(len(ids)): # for each tag found in image\n",
    "               ID = ids[i]\n",
    "               rvec = rvecs[i]\n",
    "               tvec = tvecs[i]\n",
    "               corners4 = corners[i]\n",
    "              \n",
    "               display = cv2.aruco.drawAxis(imageCopy,new_matrix,dist_matrix,rvec,tvec,0.03) # draw 3d axis, 3 centimeters\n",
    "               found_dict_pixel_space[\"\"+str(ids[i][0])] = corners4 # put the corners of this tag in the dictionary\n",
    "          \n",
    "           # Homography\n",
    "           zero = found_dict_pixel_space[str(bottom_left)][0][3] #bottom left - 3\n",
    "           x = found_dict_pixel_space[str(bottom_right)][0][2] #bottom right - 27\n",
    "           y = found_dict_pixel_space[str(top_left)][0][0] #top left - 22\n",
    "           xy = found_dict_pixel_space[str(top_right)][0][1] #top right - 24\n",
    "\n",
    "           workspace_world_corners = np.array([[0.0, 0.0], [worldx, 0.0], [0.0, worldy], [worldx, worldy]], np.float32) # 4 corners in millimeters\n",
    "           workspace_pixel_corners = np.array([zero,x,y,xy], np.float32)  # 4 corners in pixels\n",
    "\n",
    "           # Homography Matrix\n",
    "           h, status = cv2.findHomography(workspace_pixel_corners, workspace_world_corners) #perspective matrix\n",
    "           t6=time.time()-t0\n",
    "           im_out = cv2.warpPerspective(image, h, (worldx,worldy)) #showing that it works\n",
    "          \n",
    "           t7 = time.time()-t0\n",
    "           for i in range(len(ids)):\n",
    "               j = ids[i][0]\n",
    "               corners_pix = found_dict_pixel_space[str(j)]#[0]\n",
    "               corners_pix_transformed = cv2.perspectiveTransform(corners_pix,h)\n",
    "               found_dict_homography_space[str(j)] = corners_pix_transformed\n",
    "           print(found_dict_homography_space)\n",
    "           robot = found_dict_homography_space[str(robot_ID)][0]\n",
    "           print(getMarkerCenter(robot))\n",
    "           cv2.imshow('Warped Source Image', im_out)\n",
    "           t8=time.time()-t0\n",
    "           print(\"t1: %8.4f   t2: %8.4f   t3: %8.4f   t4: %8.4f   t5: %8.4f   t6: %8.4f   t7: %8.4f   t8: %8.4f\" %(t1,t2-t1,t3-t2,t4-t3,t5-t4,t6-t5,t7-t6,t8-t7))\n",
    "      \n",
    "       else:\n",
    "           display = image\n",
    "           cv2.imshow('Display', display)\n",
    "\n",
    "       ###### sending the data to the robot ########################\n",
    "       robot_center = getMarkerCenter(robot)\n",
    "       robot_angle = getMarkerRotation(robot)\n",
    "       #UDP(IP, port, str([robot_center[0], robot_center[1],robot_angle,worldx,worldy]))\n",
    "    #    UDP(IP, port, str([robot_center[0], robot_center[1], robot[1][0], robot[1][1], robot[0][0], robot[0][1], worldx, worldy]))\n",
    "\n",
    "       if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "           break\n",
    "\n",
    "except Exception as e:\n",
    " print(e)\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
